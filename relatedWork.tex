\section{Related Work}\label{sec:relatedWork}

This section discusses recent HMC methods reported in the literature that employ machine learning for protein and gene function prediction.

In Vens et al. \cite{Vens2008}, three methods based on the concept of Predictive Clustering Trees (PCT) were investigated. The authors proposed the Clus-HMC method that induces a single decision tree to cope with the entire classification problem. They compared its performance with two methods. The first one, Clus-SC, induces an independent decision tree for each class, ignoring the relationships between classes. The second one, Clus-HSC, explores the hierarchical relationships between the classes to induce a decision tree for each class. %Still based on PCT, the study of Schietgat et al. \cite{Schietgat2010} used an ensemble technique to combine the decision trees induced by Clus-HMC.

Alves et al. \cite{Alves2010} proposed a global method using Artificial Immune Systems (AIS) for the generation of HMC rules. The method is divided into two basic procedures: Sequential Covering (SC) and Rule Evolution (RE). The SC procedure iteratively calls the RE procedure until every (or almost every) training instance (antigens) is covered by the discovered rules. The RE procedure evolves classification rules (antibodies) that are employed to classify the instances. The best antibody is added to the set of discovered rules.

%An ensemble of LCN-based classifiers was proposed by Valentini \cite{Valentini2009}. In this method, each trained classifier estimates the local probability at which a given instance belongs to a given class. A combination phase estimates the global consensual probability. In \cite{ValentiniRe2009} and \cite{Valentini2011}, the authors modified this method to modulate the relationship between the prediction of a class and the prediction of its descendants.

In the work of Otero et al. \cite{Otero2010}, the authors proposed a method using Ant Colony Optimization (ACO). The method discovers classification rules, where an ACO algorithm is employed to optimize the antecedents of the rules. A sequential covering procedure is applied to create classification rules that cover most of the training instances. The method is initialized with an empty set of rules, and a new rule is added to the set while the number of instances not covered by any rule is higher than a given threshold. 

Cesa-Bianchi and Valentini \cite{Cesa-Bianchi2011} investigated the synergy between different LCN-based strategies related to gene function prediction task in FunCat annotated genes. They integrated kernel-based data fusion tools and ensemble algorithms with cost sensitive HMC methods \cite{Cesa-Bianchi2010,Valentini2011}. The authors defined synergy as the improvement in the prediction accuracy, considering any evaluation measure, due to the use of concurrent learning strategies. The synergy is detected when the combined action of two strategies achieves better correct classification rates than the average of the correct classification of the two strategies used separately~\cite{Cesa-Bianchi2011}.

Kordmahalleh et. al.~\cite{Kordmahalleh2013} proposed CAM-HMC, an evolutionary algorithm which applies evolutionary crowding niching and adaptive mutation to evolve antecedentes of HMC rules. During the evolutionary process, the authors defined a new distance measure $d$ for the competition between parents $p$ and offspring $c$. If $|d(p_1,c_1) + d(p_2,c_2)| \leq |d(p_1,c_2) + d(p_2,c_1)|$ the competition is between $(p_1,c_1)$ and $(p_2,c_2)$. Otherwise, the competition is between $(p_1,c_2)$ and $(p_2,c_1)$. The individuals with highest fitness are kept in the population. %The method also applies an adaptive range mutation introduced by Austin~\cite{Austin2002} to ensure uniform exploration of the search~space.

The work of Stojanova et. al.~\cite{Stojanova2013} proposed a method which considers autocorrelation in HMC, \emph{i.e.}, the statistical relationships between the same variable on different but related instances. The method is called Network Hierarchical Multi-label Classification (NHMC), and builds a generalized form of decision trees using the PCT framework, just like Clus-HMC. During training, NHMC uses both the features of the instances, and the autocorrelations between instances. The autocorrelations were modeled as a network, which is exploited by the method during the learning phase.

A genetic algorithm was proposed by Cerri et. al.~\cite{Cerri2014}. The method, called HMC-GA, evolves the antecedents of HMC rules, containing both propositional and relational tests. The consequents of the rules are deterministically obtained based on the classes of the training instances covered by the antecedents. Each generated rule is able to classify instances into two or more paths of the GO taxonomy.

Bi and Kwok~\cite{Bi2014} proposed a method which uses the Mandatory Leaf Node Prediction strategy (MLNP)~\cite{Silla2010}. The method uses hierarchy information, and the problem is formulated as finding the multiple labels with the largest posterior probability over all the labels. The authors extended the nested approximation property~\cite{Baraniuk2010} to deal with HMC problems structured as DAG, and solved the problem using a greedy algorithm (MAS).

In this paper, we make use of four methods reviewed in this section: Clus-HMC (which is considered to be the state-of-the-art method in the literature), Clus-HSC and Clus-SC. We also make use of the Ant Colony Optimization-based method {\it hm}Ant-Miner, which obtained competitive results with Clus-HMC. We chose these methods because they were all applied to the same datasets used in our experiments. In addition, they produce the same type of output provided by our proposed approach, and they have their code available for downloading, providing a fair base for comparison.